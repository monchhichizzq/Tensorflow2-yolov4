# -*- coding: utf-8 -*-
# @Time    : 2020/12/31 4:42
# @Author  : Zeqi@@
# @FileName: loss.py
# @Software: PyCharm
import logging
import math
import tensorflow as tf
from tensorflow.keras import backend as K
from Loss.ious import box_ciou
from tensorflow.keras.mixed_precision import experimental as mixed_precision

logging.basicConfig(format='%(asctime)s - %(name)s - %(levelname)s - %(message)s', level=logging.INFO)
logger = logging.getLogger('Loss')
logger.setLevel(logging.DEBUG)

# ---------------------------------------------------#
#   å¹³æ»‘æ ‡ç­¾
# ---------------------------------------------------#
def _smooth_labels(y_true, label_smoothing):
    num_classes = tf.cast(K.shape(y_true)[-1], dtype=K.floatx())
    label_smoothing = K.constant(label_smoothing, dtype=K.floatx())
    return y_true * (1.0 - label_smoothing) + label_smoothing / num_classes

# ---------------------------------------------------#
#   å°†é¢„æµ‹å€¼çš„æ¯ä¸ªç‰¹å¾å±‚è°ƒæˆçœŸå®å€¼
# ---------------------------------------------------#
def yolo_head(feats, anchors, num_classes, input_shape, calc_loss=False):
    '''

    :param feats: tensor, yolov4 multi-scale outputs at level l
    :param anchors: tensor, anchors at level l
    :param num_classes: int, class numbers
    :param input_shape: tuple, input image shape
    :param calc_loss:
    :return:
         box_xy:
         box_wh:
         box_confidence:
         box_class_probs:
    '''

    # Number of anchors at level l, normally 3
    num_anchors = len(anchors)

    # å§anchorsè½¬ä¸ºtensor (1, 1, 1, 3, 2) (.., .., .., num_anchors, anchor_width+anchor_height)
    anchors_tensor =  tf.cast(tf.reshape(tf.constant(anchors), [1, 1, 1, num_anchors, 2]), feats.dtype)


    # è·å¾—xï¼Œyçš„ç½‘æ ¼
    # feats: (batch, height, width, num_anchors*(num_classes + 5))
    grid_shape = tf.shape(feats)[1:3]  # ç‰¹å¾å›¾(.., h, w, .., ..)
    grid_y = tf.tile(tf.reshape(tf.keras.backend.arange(0, stop=grid_shape[0]), [-1, 1, 1, 1]),
                    [1, grid_shape[1], 1, 1])
    grid_x = tf.tile(tf.reshape(tf.keras.backend.arange(0, stop=grid_shape[1]), [1, -1, 1, 1]),
                     [grid_shape[0], 1, 1, 1])
    # grid_x = K.tile(K.reshape(K.arange(0, stop=grid_shape[1]), [1, -1, 1, 1]),
    #                 [grid_shape[0], 1, 1, 1])
    grid = tf.keras.layers.concatenate([grid_x, grid_y]) # (None, None, 1, 2)
    grid = tf.cast(grid, feats.dtype)
    # grid: (None, None, 1, 2)

    # å°† feats (batch, height, width, num_anchors*(num_classes + 5)) å˜ä¸º (batch, height, width, num_anchorsï¼Œ num_classes + 5)
    feats = tf.reshape(feats, [-1, grid_shape[0], grid_shape[1], num_anchors, num_classes + 5])

    # å°†é¢„æµ‹å€¼è°ƒæˆçœŸå®å€¼
    # box_xyå¯¹åº”æ¡†çš„ä¸­å¿ƒç‚¹
    # box_whå¯¹åº”æ¡†çš„å®½å’Œé«˜
    # å¯¹è¾“å‡ºç‰¹å¾å›¾ä¸­ç‚¹(x, y)
    # æ ¹æ®é¢„æµ‹æ¡†ä¸­å¿ƒç‚¹ä¸gridä¸­å¿ƒç‚¹ä¹‹é—´è·ç¦»(sigmoid)å¯¹é¢„æµ‹æ¡†ä¸­å¿ƒç‚¹åšè°ƒæ•´
    box_xy = (tf.keras.activations.sigmoid(feats[..., :2]) + grid) / tf.cast(grid_shape[..., ::-1], feats.dtype)

    # å¯¹é¢„æµ‹æ¡†å®½é«˜åšexpè®¡ç®—å¹¶ä¸”æ ¹æ®anchorå¤§å°ç¼©æ”¾
    box_wh = tf.math.exp(feats[..., 2:4]) * anchors_tensor / tf.cast(input_shape[..., ::-1], feats.dtype)

    # å¯¹è¾“å‡ºç‰¹å¾å›¾ä¸­ç‚¹(x, y)ä¸­confidenceå–simoidï¼Œä½¿ç½®ä¿¡åº¦å–å€¼åœ¨0åˆ°1ä¹‹é—´
    box_confidence = tf.keras.activations.sigmoid(feats[..., 4:5])
    # å¯¹è¾“å‡ºç‰¹å¾å›¾ä¸­ç‚¹(x, y)ä¸­ç±»æ¦‚ç‡å–simoidï¼Œä½¿æ¦‚ç‡å–å€¼åœ¨0åˆ°1ä¹‹é—´ï¼Œä¸€ä¸ªç‚¹å¯ä»¥æœ‰å¤šä¸ªç‰©ä½“
    box_class_probs = tf.keras.activations.sigmoid(feats[..., 5:])

    # åœ¨è®¡ç®—lossçš„æ—¶å€™è¿”å›å¦‚ä¸‹å‚æ•°
    if calc_loss == True:
        return grid, feats, box_xy, box_wh
    return box_xy, box_wh, box_confidence, box_class_probs

def bbox_ciou(boxes1, boxes2):
    '''
    è®¡ç®—ciou = iou - p2/c2 - av
    :param boxes1: (8, 13, 13, 3, 4)   pred_xywh  (13, 13, 3, 4)
    :param boxes2: (8, 13, 13, 3, 4)   label_xywh (13, 13, 3, 4)
    :return:

    ä¸¾ä¾‹æ—¶å‡è®¾pred_xywhå’Œlabel_xywhçš„shapeéƒ½æ˜¯(1, 4)
    '''

    # å˜æˆå·¦ä¸Šè§’åæ ‡ã€å³ä¸‹è§’åæ ‡
    boxes1_x0y0x1y1 = tf.concat([boxes1[..., :2] - boxes1[..., 2:] * 0.5,
                                 boxes1[..., :2] + boxes1[..., 2:] * 0.5], axis=-1)
    boxes2_x0y0x1y1 = tf.concat([boxes2[..., :2] - boxes2[..., 2:] * 0.5,
                                 boxes2[..., :2] + boxes2[..., 2:] * 0.5], axis=-1)
    '''
    é€ä¸ªä½ç½®æ¯”è¾ƒboxes1_x0y0x1y1[..., :2]å’Œboxes1_x0y0x1y1[..., 2:]ï¼Œå³é€ä¸ªä½ç½®æ¯”è¾ƒ[x0, y0]å’Œ[x1, y1]ï¼Œå°çš„ç•™ä¸‹ã€‚
    æ¯”å¦‚ç•™ä¸‹äº†[x0, y0]
    è¿™ä¸€æ­¥æ˜¯ä¸ºäº†é¿å…ä¸€å¼€å§‹w h æ˜¯è´Ÿæ•°ï¼Œå¯¼è‡´x0y0æˆäº†å³ä¸‹è§’åæ ‡ï¼Œx1y1æˆäº†å·¦ä¸Šè§’åæ ‡ã€‚
    '''
    boxes1_x0y0x1y1 = tf.concat([tf.minimum(boxes1_x0y0x1y1[..., :2], boxes1_x0y0x1y1[..., 2:]),
                                 tf.maximum(boxes1_x0y0x1y1[..., :2], boxes1_x0y0x1y1[..., 2:])], axis=-1)
    boxes2_x0y0x1y1 = tf.concat([tf.minimum(boxes2_x0y0x1y1[..., :2], boxes2_x0y0x1y1[..., 2:]),
                                 tf.maximum(boxes2_x0y0x1y1[..., :2], boxes2_x0y0x1y1[..., 2:])], axis=-1)

    # ä¸¤ä¸ªçŸ©å½¢çš„é¢ç§¯
    boxes1_area = (boxes1_x0y0x1y1[..., 2] - boxes1_x0y0x1y1[..., 0]) * (
                boxes1_x0y0x1y1[..., 3] - boxes1_x0y0x1y1[..., 1])
    boxes2_area = (boxes2_x0y0x1y1[..., 2] - boxes2_x0y0x1y1[..., 0]) * (
                boxes2_x0y0x1y1[..., 3] - boxes2_x0y0x1y1[..., 1])

    # ç›¸äº¤çŸ©å½¢çš„å·¦ä¸Šè§’åæ ‡ã€å³ä¸‹è§’åæ ‡ï¼Œshape éƒ½æ˜¯ (8, 13, 13, 3, 2)
    left_up = tf.maximum(boxes1_x0y0x1y1[..., :2], boxes2_x0y0x1y1[..., :2])
    right_down = tf.minimum(boxes1_x0y0x1y1[..., 2:], boxes2_x0y0x1y1[..., 2:])

    # ç›¸äº¤çŸ©å½¢çš„é¢ç§¯inter_areaã€‚iou
    inter_section = tf.maximum(right_down - left_up, 0.0)
    inter_area = inter_section[..., 0] * inter_section[..., 1]
    union_area = boxes1_area + boxes2_area - inter_area
    iou = inter_area / (union_area + K.epsilon())

    # åŒ…å›´çŸ©å½¢çš„å·¦ä¸Šè§’åæ ‡ã€å³ä¸‹è§’åæ ‡ï¼Œshape éƒ½æ˜¯ (8, 13, 13, 3, 2)
    enclose_left_up = tf.minimum(boxes1_x0y0x1y1[..., :2], boxes2_x0y0x1y1[..., :2])
    enclose_right_down = tf.maximum(boxes1_x0y0x1y1[..., 2:], boxes2_x0y0x1y1[..., 2:])

    # åŒ…å›´çŸ©å½¢çš„å¯¹è§’çº¿çš„å¹³æ–¹ C^2
    enclose_wh = enclose_right_down - enclose_left_up
    enclose_c2 = tf.math.pow(enclose_wh[..., 0], 2) + tf.math.pow(enclose_wh[..., 1], 2)

    # ä¸¤çŸ©å½¢ä¸­å¿ƒç‚¹è·ç¦»çš„å¹³æ–¹ ğœŒ^2 (ğ´_ğ‘ğ‘¡ğ‘Ÿ,  ğµ_ğ‘ğ‘¡ğ‘Ÿ )
    p2 = tf.math.pow(boxes1[..., 0] - boxes2[..., 0], 2) + K.pow(boxes1[..., 1] - boxes2[..., 1], 2)

    # å¢åŠ avã€‚åŠ ä¸Šé™¤0ä¿æŠ¤é˜²æ­¢nanã€‚
    atan1 = tf.atan(boxes1[..., 2] / (boxes1[..., 3] + K.epsilon()))  # w_gt/h_gt
    atan2 = tf.atan(boxes2[..., 2] / (boxes2[..., 3] + K.epsilon()))  # w/h
    v = 4.0 * tf.math.pow(atan1 - atan2, 2) / (math.pi ** 2)
    a = v / (1 - iou + v)

    ciou = iou - 1.0 * p2 / enclose_c2 - 1.0 * a * v
    return ciou

# ---------------------------------------------------#
#   ç”¨äºè®¡ç®—æ¯ä¸ªé¢„æµ‹æ¡†ä¸çœŸå®æ¡†çš„iou
# ---------------------------------------------------#
def box_iou(b1, b2):
    '''

    :param b1: tensor, shape: (None, None, 3, 4), predict boxes
    :param b2: tensor, shape: (None, None, 3, 4), predict boxes
    :return:

    é€šè¿‡b1_xy å’Œ b1_whè®¡ç®— b1_mins_xy, b1_max_xy
    é€šè¿‡b2_xy å’Œ b2_whè®¡ç®— b2_mins_xy, b2_max_xy

    æ±‚b1_mins_xyï¼Œ b2_mins_xy ä¸­æœ€å¤§å€¼ å¦‚å›¾ b2_min
    æ±‚b1_max_xyï¼Œ b2_max_xy ä¸­æœ€å°å€¼   å¦‚å›¾ b1_max
    æ±‚ intersection (æœ€å¤§å€¼-æœ€å°å€¼)

           b1_minâ€”â€”â€”â€”â€”â€”â€”â€”
                |b2_min |_____
                |   |   |    |
                |â€”â€”|â€”â€”â€”â€”|b1_max
                   |_______ |b2_max

    IOU = intersection/b1_square+b2_sqaure-intersection
    '''

    # è®¡ç®—å·¦ä¸Šè§’çš„åæ ‡å’Œå³ä¸‹è§’çš„åæ ‡
    # b1 = tf.expand_dims(b1, -2) # (None, None, 3, 1, 4)
    b1_xy = b1[..., :2]
    b1_wh = b1[..., 2:4]
    b1_wh_half = b1_wh / 2.
    b1_mins = b1_xy - b1_wh_half
    b1_maxes = b1_xy + b1_wh_half

    # è®¡ç®—å·¦ä¸Šè§’å’Œå³ä¸‹è§’çš„åæ ‡
    # b2 = tf.expand_dims(b2, 0) # (1, None, None)
    b2_xy = b2[..., :2]
    b2_wh = b2[..., 2:4]
    b2_wh_half = b2_wh / 2.
    b2_mins = b2_xy - b2_wh_half
    b2_maxes = b2_xy + b2_wh_half

    # è®¡ç®—é‡åˆé¢ç§¯
    intersect_mins = tf.math.maximum(b1_mins, b2_mins)
    intersect_maxes = tf.math.minimum(b1_maxes, b2_maxes)
    intersect_wh = tf.math.maximum(intersect_maxes - intersect_mins, 0.)
    intersect_area = intersect_wh[..., 0] * intersect_wh[..., 1]
    b1_area = b1_wh[..., 0] * b1_wh[..., 1]
    b2_area = b2_wh[..., 0] * b2_wh[..., 1]
    iou = intersect_area / (b1_area + b2_area - intersect_area)

    return iou


# ---------------------------------------------------#
#   losså€¼è®¡ç®—
# ---------------------------------------------------#
"""
å¤§å¤šæ•°ç›®æ ‡æ£€æµ‹æ¨¡å‹è®¡ç®—è¯¯å·®æ—¶ï¼š
ç›´æ¥æ ¹æ®é¢„æµ‹æ¡†å’ŒçœŸå®æ¡†çš„ä¸­å¿ƒç‚¹åæ ‡ä»¥åŠå®½é«˜ä¿¡æ¯è®¾å®šMSE(å‡æ–¹è¯¯å·®ï¼‰æŸå¤±å‡½æ•°æˆ–è€…BCEæŸå¤±å‡½æ•°çš„

"""

def yolo_loss(args, anchors, num_classes, ignore_thresh=.5, label_smoothing=0.1, print_loss=False):
    policy = mixed_precision.Policy('float32')
    mixed_precision.set_policy(policy)
    logger.info('Loss Compute dtype: %s' % policy.compute_dtype)
    logger.info('Loss Variable dtype: %s' % policy.variable_dtype)

    # ä¸€å…±æœ‰ä¸‰å±‚
    num_layers = len(anchors) // 3

    # å°†é¢„æµ‹ç»“æœå’Œå®é™…ground truthåˆ†å¼€ï¼Œargsæ˜¯[*model_body.output, *y_true]
    # y_trueæ˜¯ä¸€ä¸ªåˆ—è¡¨ï¼ŒåŒ…å«ä¸‰ä¸ªç‰¹å¾å±‚ï¼Œshapeåˆ†åˆ«ä¸º(m,13,13,3,85),(m,26,26,3,85),(m,52,52,3,85)ã€‚
    # yolo_outputsæ˜¯ä¸€ä¸ªåˆ—è¡¨ï¼ŒåŒ…å«ä¸‰ä¸ªç‰¹å¾å±‚ï¼Œshapeåˆ†åˆ«ä¸º(m,13,13,255),(m,26,26,255),(m,52,52,255)ã€‚
    y_true = args[num_layers:]
    yolo_outputs = args[:num_layers]

    for i in range(3):
        y_true[i] = tf.cast(y_true[i], dtype=tf.float32)
        yolo_outputs[i] = tf.cast(yolo_outputs[i], dtype=tf.float32)
        logger.info('y_true: {}, type: {}'.format(y_true[i].shape, y_true[i].dtype))
        logger.info('yolo_outputs {}, type: {}'.format(yolo_outputs[i].shape, yolo_outputs[i].dtype))


    # å…ˆéªŒæ¡†
    # 678ä¸º142,110,  192,243,  459,401
    # 345ä¸º36,75,  76,55,  72,146
    # 012ä¸º12,16,  19,36,  40,28
    anchor_mask = [[6, 7, 8], [3, 4, 5], [0, 1, 2]] if num_layers == 3 else [[3, 4, 5], [1, 2, 3]]

    # å¾—åˆ°input_shpaeä¸º608,608
    input_shape = tf.cast(tf.shape(yolo_outputs[0])[1:3] * 32, y_true[0].dtype)

    loss = 0

    # å–å‡ºæ¯ä¸€å¼ å›¾ç‰‡
    # mçš„å€¼å°±æ˜¯batch_size
    # m = K.shape(yolo_outputs[0])[0]
    # mf = K.cast(m, K.dtype(yolo_outputs[0]))
    batch_size_m = tf.shape(yolo_outputs[0])[0]
    batch_size = tf.cast(batch_size_m, yolo_outputs[0].dtype)

    # y_trueæ˜¯ä¸€ä¸ªåˆ—è¡¨ï¼ŒåŒ…å«ä¸‰ä¸ªç‰¹å¾å±‚ï¼Œshapeåˆ†åˆ«ä¸º(m,13,13,3,85),(m,26,26,3,85),(m,52,52,3,85)ã€‚
    # yolo_outputsæ˜¯ä¸€ä¸ªåˆ—è¡¨ï¼ŒåŒ…å«ä¸‰ä¸ªç‰¹å¾å±‚ï¼Œshapeåˆ†åˆ«ä¸º(m,13,13,255),(m,26,26,255),(m,52,52,255)ã€‚
    for l in range(num_layers):
        # ä»¥ç¬¬ä¸€ä¸ªç‰¹å¾å±‚(m, 13, 13, num_anchors, (num_classes+5))ä¸ºä¾‹å­

        # y_true: (batch, 13, 13, num_anchors, x,y,w,h, object, class)
        # Object mask ï¼šåœ¨è¯¥ç‚¹æ˜¯å¦å­˜åœ¨ç‰©ä½“
        object_mask = y_true[l][..., 4:5]

        # Truth class probabilities : åˆ†ç±»
        true_class_probs = y_true[l][..., 5:]

        if label_smoothing:
            true_class_probs = _smooth_labels(true_class_probs, label_smoothing)

        # å°†yolo_outputsçš„ç‰¹å¾å±‚å¯¼å…¥headè¿›è¡Œå¤„ç†
        # grid æ˜¯ ç‰¹å¾å›¾gridä¸­çš„ä¸­å¿ƒç‚¹åæ ‡ (13, 13, 1, 2)
        # raw_pred å°±æ˜¯ feats
        # pred_xy è§£ç åçš„xy
        # pred_wh è§£ç åçš„wh
        grid, raw_pred, pred_xy, pred_wh = yolo_head(yolo_outputs[l],
                                                     anchors[anchor_mask[l]],
                                                     num_classes,
                                                     input_shape,
                                                     calc_loss=True)

        # è¿™ä¸ªæ˜¯è§£ç åçš„é¢„æµ‹çš„boxçš„ä½ç½®  (batch,13,13,3,4)
        pred_box = tf.keras.layers.concatenate([pred_xy, pred_wh])


        # æ‰¾åˆ°è´Ÿæ ·æœ¬ç¾¤ç»„ï¼Œç¬¬ä¸€æ­¥æ˜¯åˆ›å»ºä¸€ä¸ªæ•°ç»„ï¼Œ[]
        ignore_mask = tf.TensorArray(y_true[0].dtype, size=1, dynamic_size=True)

        object_mask_bool = K.cast(object_mask, 'bool') # (None, 13, 13, 3, 1)


        # å¯¹æ¯ä¸€å¼ å›¾ç‰‡è®¡ç®—ignore_mask
        def loop_body(b, ignore_mask):
            '''
            
            :param b: 
            :param ignore_mask: 
            :return: 
            '''

            # å–å‡ºç¬¬bå‰¯å›¾å†…ï¼ŒçœŸå®å­˜åœ¨çš„æ‰€æœ‰çš„boxçš„å‚æ•°
            # (None, None, 3, 4)
            true_box = tf.boolean_mask(y_true[l][b, ..., 0:4], object_mask_bool[b, ..., 0])

            # è®¡ç®—é¢„æµ‹ç»“æœä¸çœŸå®æƒ…å†µçš„iou
            # è®¡ç®—çš„ç»“æœæ˜¯æ¯ä¸ªpred_boxå’Œå…¶å®ƒæ‰€æœ‰çœŸå®æ¡†çš„iou
            iou = box_iou(pred_box[b], true_box) # (None, None, 3)
            best_iou = K.max(iou, axis=-1) # (None, None)
            # ciou = bbox_ciou(pred_box[b], true_box)
            # best_iou = tf.math.reduce_max(ciou, axis=-1)

            # å¦‚æœæŸäº›é¢„æµ‹æ¡†å’ŒçœŸå®æ¡†çš„é‡åˆç¨‹åº¦å°äº0.5ï¼Œåˆ™å¿½ç•¥ã€‚
            ignore_mask = ignore_mask.write(b, tf.cast(best_iou < ignore_thresh, true_box.dtype))
            return b + 1, ignore_mask

        # éå†æ‰€æœ‰çš„å›¾ç‰‡
        _, ignore_mask = tf.while_loop(lambda b, *args: b < batch_size_m, loop_body, [0, ignore_mask])
        print('ignore_mask', ignore_mask)

        # å°†æ¯å¹…å›¾çš„å†…å®¹å‹ç¼©ï¼Œè¿›è¡Œå¤„ç†
        ignore_mask = ignore_mask.stack()
        print('ignore_mask', ignore_mask)

        ignore_mask = K.expand_dims(ignore_mask, -1)
        print('ignore_mask', ignore_mask)

        box_loss_scale = 2 - y_true[l][..., 2:3] * y_true[l][..., 3:4] # (2-wh)

######### Loss location part 1
        # Calculate ciou loss as location loss
        raw_true_box = y_true[l][..., 0:4]
        ciou = box_ciou(pred_box, raw_true_box)
        ciou_loss = object_mask * box_loss_scale * (1 - ciou)
        ciou_loss =  K.sum(ciou_loss) / batch_size
        location_loss = ciou_loss

        # å¦‚æœè¯¥ä½ç½®æœ¬æ¥æœ‰æ¡†ï¼Œé‚£ä¹ˆè®¡ç®—1ä¸ç½®ä¿¡åº¦çš„äº¤å‰ç†µ
        # å¦‚æœè¯¥ä½ç½®æœ¬æ¥æ²¡æœ‰æ¡†ï¼Œè€Œä¸”æ»¡è¶³best_iou<ignore_threshï¼Œåˆ™è¢«è®¤å®šä¸ºè´Ÿæ ·æœ¬
        # best_iou<ignore_threshç”¨äºé™åˆ¶è´Ÿæ ·æœ¬æ•°é‡

######### Loss confidence part 2
        # print(object_mask.shape, raw_pred[..., 4:5].shape, ignore_mask.shape)
        confidence_loss = object_mask * K.binary_crossentropy(object_mask, raw_pred[..., 4:5], from_logits=True) + \
                          (1 - object_mask) * K.binary_crossentropy(object_mask, raw_pred[..., 4:5],
                                                                    from_logits=True) * ignore_mask
######### Loss class part 3
        class_loss = object_mask * K.binary_crossentropy(true_class_probs, raw_pred[..., 5:], from_logits=True)

        confidence_loss = K.sum(confidence_loss) / batch_size
        class_loss = K.sum(class_loss) / batch_size
        loss += location_loss + confidence_loss + class_loss
        print('loss', loss.shape)
    loss = K.expand_dims(loss, axis=-1)
    print('loss', loss.shape)
    return loss

